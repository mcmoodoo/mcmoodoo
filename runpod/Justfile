set shell := ["bash", "-eu", "-o", "pipefail", "-c"]

GHCR_USER := "mcmoodoo"
IMAGE := env_var_or_default("IMAGE", "ghcr.io/mcmoodoo/runpod-llama-chat")
TAG := env_var_or_default("TAG", "latest")

# RunPod serverless: pass TEMPLATE_ID, GPU_ID, DATACENTER_ID, HF_TOKEN, RUNPOD_API_KEY as needed
TEMPLATE_ID := env_var_or_default("TEMPLATE_ID", "")
GPU_ID := env_var_or_default("GPU_ID", "NVIDIA GeForce RTX 4090")
DATACENTER_ID := env_var_or_default("DATACENTER_ID", "US-KS-2")
ENDPOINT_ID := env_var_or_default("ENDPOINT_ID", "")

default:
  @just --list

ghcr-login:
  @test -n "${RUNPOD_GHCR_TOKEN:-}" || (echo "RUNPOD_GHCR_TOKEN is not set" && exit 1)
  echo "$RUNPOD_GHCR_TOKEN" | docker login ghcr.io -u {{GHCR_USER}} --password-stdin

docker-build:
  docker build -t {{IMAGE}}:{{TAG}} .

docker-push: ghcr-login docker-build
  docker push {{IMAGE}}:{{TAG}}

# --- runpodctl (set RUNPOD_API_KEY; for private image also RUNPOD_GHCR_TOKEN) ---

runpod-config:
  @test -n "${RUNPOD_API_KEY:-}" || (echo "RUNPOD_API_KEY is not set" && exit 1)
  runpodctl config --apiKey="$RUNPOD_API_KEY"

runpod-registry:
  @test -n "${RUNPOD_GHCR_TOKEN:-}" || (echo "RUNPOD_GHCR_TOKEN is not set" && exit 1)
  runpodctl registry create \
    --name ghcr-mcmoodoo \
    --username {{GHCR_USER}} \
    --password "$RUNPOD_GHCR_TOKEN"

runpod-datacenters:
  runpodctl datacenter list --output=table

runpod-gpus:
  runpodctl gpu list --output=table

runpod-template-list:
  runpodctl template list --type user --output=table

runpod-template-create:
  @test -n "${HF_TOKEN:-}" || (echo "HF_TOKEN is not set" && exit 1)
  runpodctl template create \
    --name runpod-llama-chat \
    --image {{IMAGE}}:{{TAG}} \
    --serverless \
    --docker-start-cmd "/app/start.sh" \
    --container-disk-in-gb 20 \
    --volume-mount-path /runpod-volume \
    --env '{"HF_TOKEN":"'$HF_TOKEN'","MODEL_DIR":"/runpod-volume/model","MODEL_ID":"meta-llama/Llama-3.2-3B-Instruct"}'

runpod-endpoint:
  @test -n "{{TEMPLATE_ID}}" || (echo "TEMPLATE_ID is not set (from runpod-template-create output or just runpod-template-list)" && exit 1)
  @test -n "{{GPU_ID}}" || (echo "GPU_ID is not set (from runpod-gpus)" && exit 1)
  @test -n "{{DATACENTER_ID}}" || (echo "DATACENTER_ID is not set (from runpod-datacenters)" && exit 1)
  runpodctl serverless create \
    --name llama-chat-endpoint \
    --template-id {{TEMPLATE_ID}} \
    --gpu-id "{{GPU_ID}}" \
    --data-center-ids {{DATACENTER_ID}} \
    --workers-min 0 \
    --workers-max 3 \
    --gpu-count 1

runpod-list:
  runpodctl serverless list --output=table

runpod-get:
  @test -n "{{ENDPOINT_ID}}" || (echo "ENDPOINT_ID is not set" && exit 1)
  runpodctl serverless get {{ENDPOINT_ID}}

# Call the serverless endpoint (sync). Set ENDPOINT_ID and RUNPOD_API_KEY. Optional: MESSAGE (default below).
runpod-call:
  #!/usr/bin/env bash
  set -eu
  test -n "{{ENDPOINT_ID}}" || (echo "ENDPOINT_ID is not set" && exit 1)
  test -n "${RUNPOD_API_KEY:-}" || (echo "RUNPOD_API_KEY is not set" && exit 1)
  BODY=$(jq -n --arg msg "${MESSAGE:-What are your main skills?}" '{input: {message: $msg}}')
  curl -sS -X POST "https://api.runpod.ai/v2/{{ENDPOINT_ID}}/runsync" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $RUNPOD_API_KEY" \
    -d "$BODY"
